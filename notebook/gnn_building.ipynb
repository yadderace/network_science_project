{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Building Notebook\n",
    "\n",
    "This notebook builds a Graph Neural Network using the animal network data and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Interactions DataFrame\n",
    "\n",
    "Extract predator-prey relationships from the directed network to create edge data for the GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network file: ../data/largest_component.gexf\n",
      "Successfully loaded network with 1899 nodes and 2313 edges\n",
      "Network is directed: True\n"
     ]
    }
   ],
   "source": [
    "# Load the largest component network\n",
    "network_file = '../data/largest_component.gexf'\n",
    "print(f\"Loading network file: {network_file}\")\n",
    "\n",
    "try:\n",
    "    # Read the GEXF file using NetworkX\n",
    "    G = nx.read_gexf(network_file)\n",
    "    print(f\"Successfully loaded network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    print(f\"Network is directed: {G.is_directed()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading network file: {e}\")\n",
    "    G = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure Analysis:\n",
      "==================================================\n",
      "Number of nodes: 1899\n",
      "Number of edges: 2313\n",
      "Is directed: True\n",
      "Network density: 0.000642\n",
      "\n",
      "Sample nodes with attributes:\n",
      "  Node 526: {'scientific_name': 'Asimina reticulata', 'common_name': 'netted pawpaw', 'category': 'Plantae', 'label': '526'}\n",
      "  Node 4755: {'scientific_name': 'Thomisus onustus', 'common_name': 'Heather crab spider', 'category': 'Arachnida', 'label': '4755'}\n",
      "  Node 3161: {'scientific_name': 'Nerodia', 'common_name': 'Watersnakes', 'category': 'Reptilia', 'label': '3161'}\n",
      "\n",
      "Sample edges with attributes:\n",
      "  Edge 4755 -> 1835: {'id': '2663', 'weight': 1.0}\n",
      "  Edge 4755 -> 319: {'id': '2664', 'weight': 1.0}\n",
      "  Edge 4755 -> 2539: {'id': '2665', 'weight': 1.0}\n",
      "\n",
      "Degree statistics:\n",
      "  In-degree - Mean: 1.22, Max: 47, Min: 0\n",
      "  Out-degree - Mean: 1.22, Max: 46, Min: 0\n"
     ]
    }
   ],
   "source": [
    "# Explore the network structure\n",
    "if G is not None:\n",
    "    print(\"Network Structure Analysis:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "    print(f\"Is directed: {G.is_directed()}\")\n",
    "    print(f\"Network density: {nx.density(G):.6f}\")\n",
    "    \n",
    "    # Check node attributes\n",
    "    sample_nodes = list(G.nodes(data=True))[:3]\n",
    "    print(f\"\\nSample nodes with attributes:\")\n",
    "    for node_id, attributes in sample_nodes:\n",
    "        print(f\"  Node {node_id}: {attributes}\")\n",
    "    \n",
    "    # Check edge attributes (if any)\n",
    "    sample_edges = list(G.edges(data=True))[:3]\n",
    "    print(f\"\\nSample edges with attributes:\")\n",
    "    for source, target, attributes in sample_edges:\n",
    "        print(f\"  Edge {source} -> {target}: {attributes}\")\n",
    "    \n",
    "    # Node degree statistics\n",
    "    in_degrees = [d for n, d in G.in_degree()]\n",
    "    out_degrees = [d for n, d in G.out_degree()]\n",
    "    \n",
    "    print(f\"\\nDegree statistics:\")\n",
    "    print(f\"  In-degree - Mean: {np.mean(in_degrees):.2f}, Max: {max(in_degrees)}, Min: {min(in_degrees)}\")\n",
    "    print(f\"  Out-degree - Mean: {np.mean(out_degrees):.2f}, Max: {max(out_degrees)}, Min: {min(out_degrees)}\")\n",
    "else:\n",
    "    print(\"Cannot analyze network - loading failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interactions dataframe...\n",
      "==================================================\n",
      "Interactions dataframe created!\n",
      "Shape: (2313, 4)\n",
      "Columns: ['id', 'predator_scientific_name', 'prey_scientific_name', 'Y']\n",
      "\n",
      "Interactions summary:\n",
      "  Total interactions: 2313\n",
      "  Unique predators: 963\n",
      "  Unique prey: 1194\n",
      "  All Y values: [1]\n",
      "\n",
      "Data quality:\n",
      "  Unknown predator names: 0\n",
      "  Unknown prey names: 0\n"
     ]
    }
   ],
   "source": [
    "# Create interactions dataframe from network edges\n",
    "if G is not None:\n",
    "    print(\"Creating interactions dataframe...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize lists to store interaction data\n",
    "    interactions_data = []\n",
    "    \n",
    "    # Process each edge in the directed network\n",
    "    edge_count = 0\n",
    "    for source_id, target_id in G.edges():\n",
    "        edge_count += 1\n",
    "        \n",
    "        # Get node attributes\n",
    "        source_attrs = G.nodes[source_id]\n",
    "        target_attrs = G.nodes[target_id]\n",
    "        \n",
    "        # Extract scientific names\n",
    "        predator_scientific_name = source_attrs.get('scientific_name', f'Unknown_{source_id}')\n",
    "        prey_scientific_name = target_attrs.get('scientific_name', f'Unknown_{target_id}')\n",
    "        \n",
    "        # Create interaction record\n",
    "        interaction_record = {\n",
    "            'id': edge_count,  # Unique interaction ID\n",
    "            'predator_scientific_name': predator_scientific_name,\n",
    "            'prey_scientific_name': prey_scientific_name,\n",
    "            'Y': 1  # All interactions are positive (observed relationships)\n",
    "        }\n",
    "        \n",
    "        interactions_data.append(interaction_record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    interactions_df = pd.DataFrame(interactions_data)\n",
    "    \n",
    "    print(f\"Interactions dataframe created!\")\n",
    "    print(f\"Shape: {interactions_df.shape}\")\n",
    "    print(f\"Columns: {list(interactions_df.columns)}\")\n",
    "    \n",
    "    # Data summary\n",
    "    print(f\"\\nInteractions summary:\")\n",
    "    print(f\"  Total interactions: {len(interactions_df)}\")\n",
    "    print(f\"  Unique predators: {interactions_df['predator_scientific_name'].nunique()}\")\n",
    "    print(f\"  Unique prey: {interactions_df['prey_scientific_name'].nunique()}\")\n",
    "    print(f\"  All Y values: {interactions_df['Y'].unique()}\")\n",
    "    \n",
    "    # Check for any missing scientific names\n",
    "    unknown_predators = interactions_df['predator_scientific_name'].str.contains('Unknown_', na=False).sum()\n",
    "    unknown_prey = interactions_df['prey_scientific_name'].str.contains('Unknown_', na=False).sum()\n",
    "    \n",
    "    print(f\"\\nData quality:\")\n",
    "    print(f\"  Unknown predator names: {unknown_predators}\")\n",
    "    print(f\"  Unknown prey names: {unknown_prey}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot create interactions dataframe - network not loaded\")\n",
    "    interactions_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample interactions:\n",
      "============================================================\n",
      "   id predator_scientific_name prey_scientific_name  Y\n",
      "0   1         Thomisus onustus             Eupeodes  1\n",
      "1   2         Thomisus onustus           Anthophila  1\n",
      "2   3         Thomisus onustus           Lasiommata  1\n",
      "3   4         Thomisus onustus   Cacyreus marshalli  1\n",
      "4   5         Thomisus onustus            Dialictus  1\n",
      "5   6         Thomisus onustus           Oestroidea  1\n",
      "6   7         Thomisus onustus  Celastrina argiolus  1\n",
      "7   8    Stagmomantis carolina       Phoebis sennae  1\n",
      "8   9    Stagmomantis carolina            Acrididea  1\n",
      "9  10    Stagmomantis carolina   Melanoplus keeleri  1\n",
      "\n",
      "Random sample of interactions:\n",
      "        id   predator_scientific_name           prey_scientific_name  Y\n",
      "1171  1172        Halcyon albiventris                Ophiusa tirhaca  1\n",
      "2262  2263             Ardea herodias                Siren lacertina  1\n",
      "1947  1948  Panthera leo melanochaita  Connochaetes taurinus mearnsi  1\n",
      "523    524    Tamiasciurus hudsonicus                  Juglans nigra  1\n",
      "300    301             Sigelus silens                     Anthophila  1\n",
      "\n",
      "Data types:\n",
      "id                           int64\n",
      "predator_scientific_name    object\n",
      "prey_scientific_name        object\n",
      "Y                            int64\n",
      "dtype: object\n",
      "\n",
      "Y column verification:\n",
      "  All Y values are 1: True\n",
      "  Y value counts: Y\n",
      "1    2313\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display sample interactions\n",
    "if not interactions_df.empty:\n",
    "    print(\"Sample interactions:\")\n",
    "    print(\"=\"*60)\n",
    "    print(interactions_df.head(10))\n",
    "    \n",
    "    print(f\"\\nRandom sample of interactions:\")\n",
    "    if len(interactions_df) > 5:\n",
    "        sample_interactions = interactions_df.sample(5)\n",
    "        print(sample_interactions)\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"\\nData types:\")\n",
    "    print(interactions_df.dtypes)\n",
    "    \n",
    "    # Verify Y column\n",
    "    print(f\"\\nY column verification:\")\n",
    "    print(f\"  All Y values are 1: {(interactions_df['Y'] == 1).all()}\")\n",
    "    print(f\"  Y value counts: {interactions_df['Y'].value_counts()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No interactions data to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction Pattern Analysis:\n",
      "==================================================\n",
      "\n",
      "Top 10 predators (most prey):\n",
      "predator_scientific_name\n",
      "Ardea herodias                      46\n",
      "Apis mellifera                      34\n",
      "Lepidoptera                         23\n",
      "Halcyon albiventris albiventris     19\n",
      "Phidippus audax                     18\n",
      "Pandion haliaetus                   18\n",
      "Platycryptus undatus                16\n",
      "Larus glaucescens × occidentalis    16\n",
      "Larus glaucescens                   16\n",
      "Pterygota                           15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 prey (most predators):\n",
      "prey_scientific_name\n",
      "Lepidoptera       47\n",
      "Actinopterygii    22\n",
      "Diptera           21\n",
      "Magnoliopsida     17\n",
      "Pterygota         17\n",
      "Apis mellifera    17\n",
      "Araneae           16\n",
      "Ficus burkei      15\n",
      "Coleoptera        14\n",
      "Insecta           12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Species role analysis:\n",
      "  Species that are both predator and prey: 258\n",
      "  Species that are only predators: 705\n",
      "  Species that are only prey: 936\n",
      "\n",
      "Sample species that are both predator and prey:\n",
      "  - Baeolophus bicolor: predates 1 species, prey to 1 predators\n",
      "  - Toxomerus geminatus: predates 1 species, prey to 1 predators\n",
      "  - Polistes metricus: predates 2 species, prey to 1 predators\n",
      "  - Eratigena agrestis: predates 1 species, prey to 1 predators\n",
      "  - Chromolaena odorata: predates 1 species, prey to 6 predators\n"
     ]
    }
   ],
   "source": [
    "# Analyze interaction patterns\n",
    "if not interactions_df.empty:\n",
    "    print(\"Interaction Pattern Analysis:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Top predators (most outgoing connections)\n",
    "    predator_counts = interactions_df['predator_scientific_name'].value_counts()\n",
    "    print(f\"\\nTop 10 predators (most prey):\")\n",
    "    print(predator_counts.head(10))\n",
    "    \n",
    "    # Top prey (most incoming connections)\n",
    "    prey_counts = interactions_df['prey_scientific_name'].value_counts()\n",
    "    print(f\"\\nTop 10 prey (most predators):\")\n",
    "    print(prey_counts.head(10))\n",
    "    \n",
    "    # Species that are both predator and prey\n",
    "    predators_set = set(interactions_df['predator_scientific_name'])\n",
    "    prey_set = set(interactions_df['prey_scientific_name'])\n",
    "    \n",
    "    predator_prey_species = predators_set.intersection(prey_set)\n",
    "    only_predators = predators_set - prey_set\n",
    "    only_prey = prey_set - predators_set\n",
    "    \n",
    "    print(f\"\\nSpecies role analysis:\")\n",
    "    print(f\"  Species that are both predator and prey: {len(predator_prey_species)}\")\n",
    "    print(f\"  Species that are only predators: {len(only_predators)}\")\n",
    "    print(f\"  Species that are only prey: {len(only_prey)}\")\n",
    "    \n",
    "    if len(predator_prey_species) > 0:\n",
    "        print(f\"\\nSample species that are both predator and prey:\")\n",
    "        sample_both = list(predator_prey_species)[:5]\n",
    "        for species in sample_both:\n",
    "            pred_count = predator_counts.get(species, 0)\n",
    "            prey_count = prey_counts.get(species, 0)\n",
    "            print(f\"  - {species}: predates {pred_count} species, prey to {prey_count} predators\")\n",
    "    \n",
    "else:\n",
    "    print(\"No interactions data to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predator_scientific_name</th>\n",
       "      <th>prey_scientific_name</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Eupeodes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Anthophila</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Lasiommata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Cacyreus marshalli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Dialictus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Oestroidea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Celastrina argiolus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Stagmomantis carolina</td>\n",
       "      <td>Phoebis sennae</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Stagmomantis carolina</td>\n",
       "      <td>Acrididea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Stagmomantis carolina</td>\n",
       "      <td>Melanoplus keeleri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id predator_scientific_name prey_scientific_name  Y\n",
       "0   1         Thomisus onustus             Eupeodes  1\n",
       "1   2         Thomisus onustus           Anthophila  1\n",
       "2   3         Thomisus onustus           Lasiommata  1\n",
       "3   4         Thomisus onustus   Cacyreus marshalli  1\n",
       "4   5         Thomisus onustus            Dialictus  1\n",
       "5   6         Thomisus onustus           Oestroidea  1\n",
       "6   7         Thomisus onustus  Celastrina argiolus  1\n",
       "7   8    Stagmomantis carolina       Phoebis sennae  1\n",
       "8   9    Stagmomantis carolina            Acrididea  1\n",
       "9  10    Stagmomantis carolina   Melanoplus keeleri  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Save the datasets for future use\nif X_train is not None:\n    print(\"Saving GNN datasets...\")\n    print(\"=\"*30)\n    \n    # Save training data\n    train_data.to_csv('../data/gnn_train_data.csv', index=False)\n    val_data.to_csv('../data/gnn_val_data.csv', index=False)\n    test_data.to_csv('../data/gnn_test_data.csv', index=False)\n    \n    # Save the full combined dataset\n    full_dataset.to_csv('../data/gnn_full_dataset.csv', index=False)\n    \n    print(f\"Datasets saved:\")\n    print(f\"  Training data: ../data/gnn_train_data.csv ({len(train_data)} samples)\")\n    print(f\"  Validation data: ../data/gnn_val_data.csv ({len(val_data)} samples)\")\n    print(f\"  Test data: ../data/gnn_test_data.csv ({len(test_data)} samples)\")\n    print(f\"  Full dataset: ../data/gnn_full_dataset.csv ({len(full_dataset)} samples)\")\n    \n    print(f\"\\n✅ GNN Dataset Creation Complete!\")\n    print(f\"   Ready for link prediction model training\")\n    print(f\"   Variables available:\")\n    print(f\"   - train_data, val_data, test_data (DataFrames)\")\n    print(f\"   - X_train, y_train, X_val, y_val, X_test, y_test (arrays)\")\n    print(f\"   - feature_names (list of feature column names)\")\n    print(f\"   - Train/Val/Test split: {len(train_data)}/{len(val_data)}/{len(test_data)} samples\")\n    \nelse:\n    print(\"Cannot save datasets - no data available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Prepare final datasets for GNN training\nif len(train_data) > 0:\n    print(\"Preparing final GNN datasets...\")\n    print(\"=\"*50)\n    \n    # Define feature columns (exclude metadata columns)\n    metadata_cols = ['id', 'predator_scientific_name', 'prey_scientific_name', 'Y', 'link_exists']\n    feature_cols = [col for col in train_data.columns if col not in metadata_cols]\n    \n    print(f\"Dataset preparation:\")\n    print(f\"  Total columns: {len(train_data.columns)}\")\n    print(f\"  Metadata columns: {len(metadata_cols)} - {metadata_cols}\")\n    print(f\"  Feature columns: {len(feature_cols)}\")\n    \n    # Separate features and labels for each split\n    def prepare_split(data, split_name):\n        features = data[feature_cols].values\n        labels = data['link_exists'].values\n        metadata = data[metadata_cols]\n        \n        print(f\"  {split_name}:\")\n        print(f\"    Features shape: {features.shape}\")\n        print(f\"    Labels shape: {labels.shape}\")\n        print(f\"    Positive labels: {labels.sum()} ({labels.mean()*100:.1f}%)\")\n        \n        return features, labels, metadata\n    \n    print(f\"\\nPreparing splits:\")\n    X_train, y_train, train_metadata = prepare_split(train_data, \"Training\")\n    X_val, y_val, val_metadata = prepare_split(val_data, \"Validation\")\n    X_test, y_test, test_metadata = prepare_split(test_data, \"Test\")\n    \n    print(f\"\\n✅ GNN datasets ready for training!\")\n    print(f\"   Training: X_train {X_train.shape}, y_train {y_train.shape}\")\n    print(f\"   Validation: X_val {X_val.shape}, y_val {y_val.shape}\")\n    print(f\"   Test: X_test {X_test.shape}, y_test {y_test.shape}\")\n    \n    # Save feature column names for later use\n    feature_names = feature_cols.copy()\n    print(f\"   Feature names saved: {len(feature_names)} features\")\n    \n    # Display sample features for verification\n    print(f\"\\nSample feature columns:\")\n    predator_features = [col for col in feature_cols if col.startswith('predator_')][:5]\n    prey_features = [col for col in feature_cols if col.startswith('prey_')][:5]\n    print(f\"  Predator features (first 5): {predator_features}\")\n    print(f\"  Prey features (first 5): {prey_features}\")\n    \nelse:\n    print(\"Cannot prepare final datasets - no training data available\")\n    X_train = y_train = X_val = y_val = X_test = y_test = None\n    train_metadata = val_metadata = test_metadata = pd.DataFrame()\n    feature_names = []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Split data into training, validation, and test sets\nif len(full_dataset) > 0:\n    print(\"Splitting data into train/validation/test sets...\")\n    print(\"=\"*50)\n    \n    # Shuffle the dataset\n    shuffled_dataset = full_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    # Define split ratios\n    train_ratio = 0.7\n    val_ratio = 0.15\n    test_ratio = 0.15\n    \n    # Calculate split indices\n    total_samples = len(shuffled_dataset)\n    train_size = int(total_samples * train_ratio)\n    val_size = int(total_samples * val_ratio)\n    test_size = total_samples - train_size - val_size\n    \n    # Split the data\n    train_data = shuffled_dataset[:train_size].copy()\n    val_data = shuffled_dataset[train_size:train_size + val_size].copy()\n    test_data = shuffled_dataset[train_size + val_size:].copy()\n    \n    print(f\"Data split completed:\")\n    print(f\"  Total samples: {total_samples}\")\n    print(f\"  Training set: {len(train_data)} samples ({len(train_data)/total_samples*100:.1f}%)\")\n    print(f\"  Validation set: {len(val_data)} samples ({len(val_data)/total_samples*100:.1f}%)\")\n    print(f\"  Test set: {len(test_data)} samples ({len(test_data)/total_samples*100:.1f}%)\")\n    \n    # Check label distribution in each split\n    def check_label_distribution(data, split_name):\n        label_counts = data['link_exists'].value_counts().sort_index()\n        pos_count = label_counts.get(1, 0)\n        neg_count = label_counts.get(0, 0)\n        total = len(data)\n        \n        print(f\"  {split_name}:\")\n        print(f\"    Positive (links): {pos_count} ({pos_count/total*100:.1f}%)\")\n        print(f\"    Negative (no-links): {neg_count} ({neg_count/total*100:.1f}%)\")\n    \n    print(f\"\\nLabel distribution by split:\")\n    check_label_distribution(train_data, \"Training\")\n    check_label_distribution(val_data, \"Validation\")\n    check_label_distribution(test_data, \"Test\")\n    \nelse:\n    print(\"Cannot split data - no full dataset available\")\n    train_data = val_data = test_data = pd.DataFrame()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Combine positive and negative samples\nif len(positive_samples) > 0 and len(negative_samples) > 0:\n    print(\"Combining positive and negative samples...\")\n    print(\"=\"*50)\n    \n    # Combine datasets\n    full_dataset = pd.concat([positive_samples, negative_samples], ignore_index=True)\n    \n    print(f\"Combined dataset:\")\n    print(f\"  Total samples: {len(full_dataset)}\")\n    print(f\"  Positive samples: {len(positive_samples)} ({len(positive_samples)/len(full_dataset)*100:.1f}%)\")\n    print(f\"  Negative samples: {len(negative_samples)} ({len(negative_samples)/len(full_dataset)*100:.1f}%)\")\n    print(f\"  Shape: {full_dataset.shape}\")\n    \n    # Verify label distribution\n    label_counts = full_dataset['link_exists'].value_counts().sort_index()\n    print(f\"\\nLabel distribution:\")\n    for label, count in label_counts.items():\n        label_name = \"No-link\" if label == 0 else \"Link exists\"\n        print(f\"  {label} ({label_name}): {count} samples\")\n    \n    # Check for missing values\n    missing_counts = full_dataset.isnull().sum()\n    total_missing = missing_counts.sum()\n    \n    print(f\"\\nData quality check:\")\n    print(f\"  Total missing values: {total_missing}\")\n    if total_missing > 0:\n        print(f\"  Columns with missing values:\")\n        for col, count in missing_counts[missing_counts > 0].items():\n            print(f\"    {col}: {count} missing\")\n    else:\n        print(f\"  ✅ No missing values!\")\n    \nelse:\n    print(\"Cannot combine samples - missing positive or negative data\")\n    full_dataset = pd.DataFrame()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate negative samples (no-links)\nif len(positive_samples) > 0 and len(valid_species) > 1:\n    print(\"Generating negative samples (no-links)...\")\n    print(\"=\"*50)\n    \n    # Create set of existing interactions for fast lookup\n    existing_links = set(zip(positive_samples['predator_scientific_name'], \n                           positive_samples['prey_scientific_name']))\n    \n    print(f\"Existing links to avoid: {len(existing_links)}\")\n    \n    # Convert valid species to list for random sampling\n    species_list = list(valid_species)\n    num_species = len(species_list)\n    \n    # Generate negative samples (equal number to positive samples)\n    num_negative_samples = len(positive_samples)\n    negative_samples_data = []\n    \n    print(f\"Generating {num_negative_samples} negative samples...\")\n    \n    # Get animals_features for merging with negative samples\n    animals_features_dict = animals_features.set_index('scientific_name').to_dict('index')\n    \n    attempts = 0\n    max_attempts = num_negative_samples * 10  # Avoid infinite loop\n    \n    while len(negative_samples_data) < num_negative_samples and attempts < max_attempts:\n        attempts += 1\n        \n        # Randomly sample predator and prey\n        predator = np.random.choice(species_list)\n        prey = np.random.choice(species_list)\n        \n        # Skip self-loops and existing links\n        if predator != prey and (predator, prey) not in existing_links:\n            # Check if both species have features\n            if predator in animals_features_dict and prey in animals_features_dict:\n                \n                # Create negative sample with features\n                negative_sample = {\n                    'id': len(positive_samples) + len(negative_samples_data) + 1,\n                    'predator_scientific_name': predator,\n                    'prey_scientific_name': prey,\n                    'Y': 0,  # Keep original Y column\n                    'link_exists': 0  # Label for no-link\n                }\n                \n                # Add predator features\n                predator_features = animals_features_dict[predator]\n                for feature_name, feature_value in predator_features.items():\n                    if feature_name != 'scientific_name':\n                        negative_sample[f'predator_{feature_name}'] = feature_value\n                \n                # Add prey features  \n                prey_features = animals_features_dict[prey]\n                for feature_name, feature_value in prey_features.items():\n                    if feature_name != 'scientific_name':\n                        negative_sample[f'prey_{feature_name}'] = feature_value\n                \n                negative_samples_data.append(negative_sample)\n    \n    # Create negative samples dataframe\n    negative_samples = pd.DataFrame(negative_samples_data)\n    \n    print(f\"Successfully generated {len(negative_samples)} negative samples\")\n    print(f\"Attempts required: {attempts}\")\n    print(f\"Shape: {negative_samples.shape}\")\n    \n    # Display sample negative data\n    print(f\"\\nSample negative interactions:\")\n    sample_cols = ['id', 'predator_scientific_name', 'prey_scientific_name', 'link_exists']\n    if len(negative_samples) > 0:\n        print(negative_samples[sample_cols].head(3))\n    \nelse:\n    print(\"Cannot generate negative samples - insufficient positive data\")\n    negative_samples = pd.DataFrame()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Prepare positive samples (existing interactions)\nif not interactions_with_all_features.empty:\n    print(\"Preparing positive samples for link prediction...\")\n    print(\"=\"*50)\n    \n    # Filter out interactions with missing features (complete cases only)\n    complete_interactions = interactions_with_all_features.dropna()\n    \n    print(f\"Original interactions: {len(interactions_with_all_features)}\")\n    print(f\"Complete interactions (no missing features): {len(complete_interactions)}\")\n    \n    # Create positive samples dataframe\n    positive_samples = complete_interactions.copy()\n    positive_samples['link_exists'] = 1  # Label for existing links\n    \n    print(f\"Positive samples created: {len(positive_samples)}\")\n    print(f\"Shape: {positive_samples.shape}\")\n    \n    # Get unique species that have complete features\n    valid_species = set(complete_interactions['predator_scientific_name']) | set(complete_interactions['prey_scientific_name'])\n    print(f\"Valid species for dataset: {len(valid_species)}\")\n    \n    # Display sample positive data\n    print(f\"\\nSample positive interactions:\")\n    sample_cols = ['id', 'predator_scientific_name', 'prey_scientific_name', 'link_exists']\n    print(positive_samples[sample_cols].head(3))\n    \nelse:\n    print(\"Cannot create positive samples - no interaction data available\")\n    positive_samples = pd.DataFrame()\n    valid_species = set()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Creating GNN Dataset for Link Prediction\n\nPrepare the dataset for training a GNN model to predict new animal interactions. This includes creating positive samples (existing links) and negative samples (no-links), then splitting into training, validation, and test sets.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Features with Interactions\n",
    "\n",
    "Merge animal features from animals_transformed.csv with the interactions dataframe for both predator and prey species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animal features: ../data/animals_transformed.csv\n",
      "Successfully loaded animal features with shape: (1237, 26)\n",
      "Columns: ['scientific_name', 'weight_normalized', 'size_normalized', 'life_span_normalized', 'diet_Carnivore', 'diet_Herbivore', 'diet_Insectivore', 'diet_Omnivore', 'habitat_Forest', 'habitat_Grassland', 'habitat_Garden', 'habitat_Urban', 'habitat_Woodland', 'habitat_Shrubland', 'habitat_Wetland', 'habitat_Savanna', 'habitat_Meadow', 'habitat_Gardens', 'habitat_other', 'continent_Europe', 'continent_Asia', 'continent_Africa', 'continent_North_America', 'continent_Central_America', 'continent_South_America', 'continent_Oceania']\n",
      "\n",
      "Animal features dataframe info:\n",
      "  Number of animals: 1237\n",
      "  Columns: 26\n",
      "\n",
      "Sample animal features:\n",
      "         scientific_name  weight_normalized  size_normalized  \\\n",
      "0       Thomisus onustus       9.994803e-10         0.000000   \n",
      "1                Nerodia       1.099450e-05         0.066667   \n",
      "2  Stagmomantis carolina       3.997999e-08         0.003175   \n",
      "\n",
      "   life_span_normalized  diet_Carnivore  diet_Herbivore  diet_Insectivore  \\\n",
      "0              0.009066               0               0                 1   \n",
      "1              0.068159               1               0                 0   \n",
      "2              0.006793               0               0                 1   \n",
      "\n",
      "   diet_Omnivore  habitat_Forest  habitat_Grassland  ...  habitat_Meadow  \\\n",
      "0              0               0                  0  ...               1   \n",
      "1              0               0                  0  ...               0   \n",
      "2              0               1                  1  ...               0   \n",
      "\n",
      "   habitat_Gardens  habitat_other  continent_Europe  continent_Asia  \\\n",
      "0                0              0                 1               1   \n",
      "1                0              1                 0               0   \n",
      "2                0              0                 0               0   \n",
      "\n",
      "   continent_Africa  continent_North_America  continent_Central_America  \\\n",
      "0                 1                        0                          0   \n",
      "1                 0                        1                          0   \n",
      "2                 0                        1                          1   \n",
      "\n",
      "   continent_South_America  continent_Oceania  \n",
      "0                        0                  0  \n",
      "1                        0                  0  \n",
      "2                        0                  0  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load animal features from animals_transformed.csv\n",
    "features_file = '../data/animals_transformed.csv'\n",
    "print(f\"Loading animal features: {features_file}\")\n",
    "\n",
    "try:\n",
    "    # Load the transformed animal features\n",
    "    animals_features = pd.read_csv(features_file)\n",
    "    print(f\"Successfully loaded animal features with shape: {animals_features.shape}\")\n",
    "    print(f\"Columns: {list(animals_features.columns)}\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"\\nAnimal features dataframe info:\")\n",
    "    print(f\"  Number of animals: {len(animals_features)}\")\n",
    "    print(f\"  Columns: {len(animals_features.columns)}\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(f\"\\nSample animal features:\")\n",
    "    print(animals_features.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading features file: {e}\")\n",
    "    animals_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging predator features...\n",
      "========================================\n",
      "Shape after merging predator features: (2313, 29)\n",
      "New predator feature columns: ['predator_weight_normalized', 'predator_size_normalized', 'predator_life_span_normalized', 'predator_diet_Carnivore', 'predator_diet_Herbivore', 'predator_diet_Insectivore', 'predator_diet_Omnivore', 'predator_habitat_Forest', 'predator_habitat_Grassland', 'predator_habitat_Garden', 'predator_habitat_Urban', 'predator_habitat_Woodland', 'predator_habitat_Shrubland', 'predator_habitat_Wetland', 'predator_habitat_Savanna', 'predator_habitat_Meadow', 'predator_habitat_Gardens', 'predator_habitat_other', 'predator_continent_Europe', 'predator_continent_Asia', 'predator_continent_Africa', 'predator_continent_North_America', 'predator_continent_Central_America', 'predator_continent_South_America', 'predator_continent_Oceania']\n",
      "Interactions with complete predator features: 1956/2313\n"
     ]
    }
   ],
   "source": [
    "# Merge predator features with interactions dataframe\n",
    "if not animals_features.empty and not interactions_df.empty:\n",
    "    print(\"Merging predator features...\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Merge predator features\n",
    "    interactions_with_predator_features = interactions_df.merge(\n",
    "        animals_features, \n",
    "        left_on='predator_scientific_name', \n",
    "        right_on='scientific_name', \n",
    "        how='left',\n",
    "        suffixes=('', '_predator')\n",
    "    )\n",
    "    \n",
    "    # Rename feature columns to include 'predator_' prefix\n",
    "    predator_feature_columns = [col for col in animals_features.columns if col != 'scientific_name']\n",
    "    \n",
    "    # Create mapping for renaming columns\n",
    "    column_rename_map = {}\n",
    "    for col in predator_feature_columns:\n",
    "        if col in interactions_with_predator_features.columns:\n",
    "            column_rename_map[col] = f'predator_{col}'\n",
    "    \n",
    "    # Rename columns\n",
    "    interactions_with_predator_features = interactions_with_predator_features.rename(columns=column_rename_map)\n",
    "    \n",
    "    # Drop the duplicate scientific_name column from merge\n",
    "    if 'scientific_name' in interactions_with_predator_features.columns:\n",
    "        interactions_with_predator_features = interactions_with_predator_features.drop('scientific_name', axis=1)\n",
    "    \n",
    "    print(f\"Shape after merging predator features: {interactions_with_predator_features.shape}\")\n",
    "    print(f\"New predator feature columns: {[col for col in interactions_with_predator_features.columns if col.startswith('predator_') and col != 'predator_scientific_name']}\")\n",
    "    \n",
    "    # Check merge success\n",
    "    predator_features_merged = interactions_with_predator_features[[col for col in interactions_with_predator_features.columns if col.startswith('predator_') and col != 'predator_scientific_name']].notna().all(axis=1).sum()\n",
    "    \n",
    "    print(f\"Interactions with complete predator features: {predator_features_merged}/{len(interactions_with_predator_features)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot merge predator features - missing data\")\n",
    "    interactions_with_predator_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging prey features...\n",
      "========================================\n",
      "Shape after merging prey features: (2313, 54)\n",
      "New prey feature columns: ['prey_weight_normalized', 'prey_size_normalized', 'prey_life_span_normalized', 'prey_diet_Carnivore', 'prey_diet_Herbivore', 'prey_diet_Insectivore', 'prey_diet_Omnivore', 'prey_habitat_Forest', 'prey_habitat_Grassland', 'prey_habitat_Garden', 'prey_habitat_Urban', 'prey_habitat_Woodland', 'prey_habitat_Shrubland', 'prey_habitat_Wetland', 'prey_habitat_Savanna', 'prey_habitat_Meadow', 'prey_habitat_Gardens', 'prey_habitat_other', 'prey_continent_Europe', 'prey_continent_Asia', 'prey_continent_Africa', 'prey_continent_North_America', 'prey_continent_Central_America', 'prey_continent_South_America', 'prey_continent_Oceania']\n",
      "Interactions with complete prey features: 1180/2313\n",
      "\n",
      "Final combined dataframe:\n",
      "  Shape: (2313, 54)\n",
      "  Columns: 54\n",
      "  Predator feature columns: 25\n",
      "  Prey feature columns: 25\n",
      "  Total feature columns: 50\n"
     ]
    }
   ],
   "source": [
    "# Merge prey features with interactions dataframe\n",
    "if not animals_features.empty and not interactions_with_predator_features.empty:\n",
    "    print(\"Merging prey features...\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Merge prey features\n",
    "    interactions_with_all_features = interactions_with_predator_features.merge(\n",
    "        animals_features, \n",
    "        left_on='prey_scientific_name', \n",
    "        right_on='scientific_name', \n",
    "        how='left',\n",
    "        suffixes=('', '_prey')\n",
    "    )\n",
    "    \n",
    "    # Rename feature columns to include 'prey_' prefix\n",
    "    prey_feature_columns = [col for col in animals_features.columns if col != 'scientific_name']\n",
    "    \n",
    "    # Create mapping for renaming columns (avoid conflicts with predator columns)\n",
    "    column_rename_map = {}\n",
    "    for col in prey_feature_columns:\n",
    "        if col in interactions_with_all_features.columns and not col.startswith('predator_'):\n",
    "            column_rename_map[col] = f'prey_{col}'\n",
    "    \n",
    "    # Rename columns\n",
    "    interactions_with_all_features = interactions_with_all_features.rename(columns=column_rename_map)\n",
    "    \n",
    "    # Drop the duplicate scientific_name column from merge\n",
    "    if 'scientific_name' in interactions_with_all_features.columns:\n",
    "        interactions_with_all_features = interactions_with_all_features.drop('scientific_name', axis=1)\n",
    "    \n",
    "    print(f\"Shape after merging prey features: {interactions_with_all_features.shape}\")\n",
    "    print(f\"New prey feature columns: {[col for col in interactions_with_all_features.columns if col.startswith('prey_') and col != 'prey_scientific_name']}\")\n",
    "    \n",
    "    # Check merge success\n",
    "    prey_features_merged = interactions_with_all_features[[col for col in interactions_with_all_features.columns if col.startswith('prey_') and col != 'prey_scientific_name']].notna().all(axis=1).sum()\n",
    "    \n",
    "    print(f\"Interactions with complete prey features: {prey_features_merged}/{len(interactions_with_all_features)}\")\n",
    "    \n",
    "    # Final dataframe summary\n",
    "    print(f\"\\nFinal combined dataframe:\")\n",
    "    print(f\"  Shape: {interactions_with_all_features.shape}\")\n",
    "    print(f\"  Columns: {len(interactions_with_all_features.columns)}\")\n",
    "    \n",
    "    # Count feature columns\n",
    "    predator_feature_cols = [col for col in interactions_with_all_features.columns if col.startswith('predator_') and col != 'predator_scientific_name']\n",
    "    prey_feature_cols = [col for col in interactions_with_all_features.columns if col.startswith('prey_') and col != 'prey_scientific_name']\n",
    "    \n",
    "    print(f\"  Predator feature columns: {len(predator_feature_cols)}\")\n",
    "    print(f\"  Prey feature columns: {len(prey_feature_cols)}\")\n",
    "    print(f\"  Total feature columns: {len(predator_feature_cols) + len(prey_feature_cols)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot merge prey features - missing data\")\n",
    "    interactions_with_all_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of combined interactions with features:\n",
      "============================================================\n",
      "First 3 interactions with all features:\n",
      "   id predator_scientific_name prey_scientific_name  Y  \\\n",
      "0   1         Thomisus onustus             Eupeodes  1   \n",
      "1   2         Thomisus onustus           Anthophila  1   \n",
      "2   3         Thomisus onustus           Lasiommata  1   \n",
      "\n",
      "   predator_weight_normalized  predator_size_normalized  \\\n",
      "0                9.994803e-10                       0.0   \n",
      "1                9.994803e-10                       0.0   \n",
      "2                9.994803e-10                       0.0   \n",
      "\n",
      "   predator_life_span_normalized  predator_diet_Carnivore  \\\n",
      "0                       0.009066                      0.0   \n",
      "1                       0.009066                      0.0   \n",
      "2                       0.009066                      0.0   \n",
      "\n",
      "   predator_diet_Herbivore  predator_diet_Insectivore  ...  \\\n",
      "0                      0.0                        1.0  ...   \n",
      "1                      0.0                        1.0  ...   \n",
      "2                      0.0                        1.0  ...   \n",
      "\n",
      "   prey_habitat_Meadow  prey_habitat_Gardens  prey_habitat_other  \\\n",
      "0                  1.0                   0.0                 1.0   \n",
      "1                  1.0                   0.0                 1.0   \n",
      "2                  0.0                   1.0                 1.0   \n",
      "\n",
      "   prey_continent_Europe  prey_continent_Asia  prey_continent_Africa  \\\n",
      "0                    1.0                  1.0                    0.0   \n",
      "1                    1.0                  1.0                    1.0   \n",
      "2                    1.0                  1.0                    1.0   \n",
      "\n",
      "   prey_continent_North_America  prey_continent_Central_America  \\\n",
      "0                           1.0                             0.0   \n",
      "1                           1.0                             0.0   \n",
      "2                           0.0                             0.0   \n",
      "\n",
      "   prey_continent_South_America  prey_continent_Oceania  \n",
      "0                           0.0                     0.0  \n",
      "1                           1.0                     1.0  \n",
      "2                           0.0                     0.0  \n",
      "\n",
      "[3 rows x 54 columns]\n",
      "\n",
      "Column organization:\n",
      "  Basic columns (4): ['id', 'predator_scientific_name', 'prey_scientific_name', 'Y']\n",
      "  Predator features (25): ['predator_weight_normalized', 'predator_size_normalized', 'predator_life_span_normalized', 'predator_diet_Carnivore', 'predator_diet_Herbivore']...\n",
      "  Prey features (25): ['prey_weight_normalized', 'prey_size_normalized', 'prey_life_span_normalized', 'prey_diet_Carnivore', 'prey_diet_Herbivore']...\n",
      "\n",
      "Columns with missing values:\n",
      "  predator_weight_normalized: 357 missing values (15.4%)\n",
      "  predator_size_normalized: 357 missing values (15.4%)\n",
      "  predator_life_span_normalized: 357 missing values (15.4%)\n",
      "  predator_diet_Carnivore: 357 missing values (15.4%)\n",
      "  predator_diet_Herbivore: 357 missing values (15.4%)\n",
      "  predator_diet_Insectivore: 357 missing values (15.4%)\n",
      "  predator_diet_Omnivore: 357 missing values (15.4%)\n",
      "  predator_habitat_Forest: 357 missing values (15.4%)\n",
      "  predator_habitat_Grassland: 357 missing values (15.4%)\n",
      "  predator_habitat_Garden: 357 missing values (15.4%)\n",
      "  predator_habitat_Urban: 357 missing values (15.4%)\n",
      "  predator_habitat_Woodland: 357 missing values (15.4%)\n",
      "  predator_habitat_Shrubland: 357 missing values (15.4%)\n",
      "  predator_habitat_Wetland: 357 missing values (15.4%)\n",
      "  predator_habitat_Savanna: 357 missing values (15.4%)\n",
      "  predator_habitat_Meadow: 357 missing values (15.4%)\n",
      "  predator_habitat_Gardens: 357 missing values (15.4%)\n",
      "  predator_habitat_other: 357 missing values (15.4%)\n",
      "  predator_continent_Europe: 357 missing values (15.4%)\n",
      "  predator_continent_Asia: 357 missing values (15.4%)\n",
      "  predator_continent_Africa: 357 missing values (15.4%)\n",
      "  predator_continent_North_America: 357 missing values (15.4%)\n",
      "  predator_continent_Central_America: 357 missing values (15.4%)\n",
      "  predator_continent_South_America: 357 missing values (15.4%)\n",
      "  predator_continent_Oceania: 357 missing values (15.4%)\n",
      "  prey_weight_normalized: 1133 missing values (49.0%)\n",
      "  prey_size_normalized: 1133 missing values (49.0%)\n",
      "  prey_life_span_normalized: 1133 missing values (49.0%)\n",
      "  prey_diet_Carnivore: 1133 missing values (49.0%)\n",
      "  prey_diet_Herbivore: 1133 missing values (49.0%)\n",
      "  prey_diet_Insectivore: 1133 missing values (49.0%)\n",
      "  prey_diet_Omnivore: 1133 missing values (49.0%)\n",
      "  prey_habitat_Forest: 1133 missing values (49.0%)\n",
      "  prey_habitat_Grassland: 1133 missing values (49.0%)\n",
      "  prey_habitat_Garden: 1133 missing values (49.0%)\n",
      "  prey_habitat_Urban: 1133 missing values (49.0%)\n",
      "  prey_habitat_Woodland: 1133 missing values (49.0%)\n",
      "  prey_habitat_Shrubland: 1133 missing values (49.0%)\n",
      "  prey_habitat_Wetland: 1133 missing values (49.0%)\n",
      "  prey_habitat_Savanna: 1133 missing values (49.0%)\n",
      "  prey_habitat_Meadow: 1133 missing values (49.0%)\n",
      "  prey_habitat_Gardens: 1133 missing values (49.0%)\n",
      "  prey_habitat_other: 1133 missing values (49.0%)\n",
      "  prey_continent_Europe: 1133 missing values (49.0%)\n",
      "  prey_continent_Asia: 1133 missing values (49.0%)\n",
      "  prey_continent_Africa: 1133 missing values (49.0%)\n",
      "  prey_continent_North_America: 1133 missing values (49.0%)\n",
      "  prey_continent_Central_America: 1133 missing values (49.0%)\n",
      "  prey_continent_South_America: 1133 missing values (49.0%)\n",
      "  prey_continent_Oceania: 1133 missing values (49.0%)\n",
      "\n",
      "✅ Combined dataframe ready for GNN!\n",
      "   Variable: 'interactions_with_all_features'\n",
      "   Shape: (2313, 54)\n",
      "   Total interactions: 2313\n"
     ]
    }
   ],
   "source": [
    "# Display sample of the combined dataframe\n",
    "if not interactions_with_all_features.empty:\n",
    "    print(\"Sample of combined interactions with features:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"First 3 interactions with all features:\")\n",
    "    print(interactions_with_all_features.head(3))\n",
    "    \n",
    "    # Display columns organized by type\n",
    "    all_columns = list(interactions_with_all_features.columns)\n",
    "    basic_columns = ['id', 'predator_scientific_name', 'prey_scientific_name', 'Y']\n",
    "    predator_columns = [col for col in all_columns if col.startswith('predator_') and col != 'predator_scientific_name']\n",
    "    prey_columns = [col for col in all_columns if col.startswith('prey_') and col != 'prey_scientific_name']\n",
    "    \n",
    "    print(f\"\\nColumn organization:\")\n",
    "    print(f\"  Basic columns ({len(basic_columns)}): {basic_columns}\")\n",
    "    print(f\"  Predator features ({len(predator_columns)}): {predator_columns[:5]}{'...' if len(predator_columns) > 5 else ''}\")\n",
    "    print(f\"  Prey features ({len(prey_columns)}): {prey_columns[:5]}{'...' if len(prey_columns) > 5 else ''}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_counts = interactions_with_all_features.isnull().sum()\n",
    "    columns_with_missing = missing_counts[missing_counts > 0]\n",
    "    \n",
    "    if len(columns_with_missing) > 0:\n",
    "        print(f\"\\nColumns with missing values:\")\n",
    "        for col, count in columns_with_missing.items():\n",
    "            print(f\"  {col}: {count} missing values ({count/len(interactions_with_all_features)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n✅ No missing values in combined dataframe!\")\n",
    "    \n",
    "    print(f\"\\n✅ Combined dataframe ready for GNN!\")\n",
    "    print(f\"   Variable: 'interactions_with_all_features'\")\n",
    "    print(f\"   Shape: {interactions_with_all_features.shape}\")\n",
    "    print(f\"   Total interactions: {len(interactions_with_all_features)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No combined dataframe to display\")~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predator_scientific_name</th>\n",
       "      <th>prey_scientific_name</th>\n",
       "      <th>Y</th>\n",
       "      <th>predator_weight_normalized</th>\n",
       "      <th>predator_size_normalized</th>\n",
       "      <th>predator_life_span_normalized</th>\n",
       "      <th>predator_diet_Carnivore</th>\n",
       "      <th>predator_diet_Herbivore</th>\n",
       "      <th>predator_diet_Insectivore</th>\n",
       "      <th>...</th>\n",
       "      <th>prey_habitat_Meadow</th>\n",
       "      <th>prey_habitat_Gardens</th>\n",
       "      <th>prey_habitat_other</th>\n",
       "      <th>prey_continent_Europe</th>\n",
       "      <th>prey_continent_Asia</th>\n",
       "      <th>prey_continent_Africa</th>\n",
       "      <th>prey_continent_North_America</th>\n",
       "      <th>prey_continent_Central_America</th>\n",
       "      <th>prey_continent_South_America</th>\n",
       "      <th>prey_continent_Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Eupeodes</td>\n",
       "      <td>1</td>\n",
       "      <td>9.994803e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Anthophila</td>\n",
       "      <td>1</td>\n",
       "      <td>9.994803e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Lasiommata</td>\n",
       "      <td>1</td>\n",
       "      <td>9.994803e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Cacyreus marshalli</td>\n",
       "      <td>1</td>\n",
       "      <td>9.994803e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Thomisus onustus</td>\n",
       "      <td>Dialictus</td>\n",
       "      <td>1</td>\n",
       "      <td>9.994803e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id predator_scientific_name prey_scientific_name  Y  \\\n",
       "0   1         Thomisus onustus             Eupeodes  1   \n",
       "1   2         Thomisus onustus           Anthophila  1   \n",
       "2   3         Thomisus onustus           Lasiommata  1   \n",
       "3   4         Thomisus onustus   Cacyreus marshalli  1   \n",
       "4   5         Thomisus onustus            Dialictus  1   \n",
       "\n",
       "   predator_weight_normalized  predator_size_normalized  \\\n",
       "0                9.994803e-10                       0.0   \n",
       "1                9.994803e-10                       0.0   \n",
       "2                9.994803e-10                       0.0   \n",
       "3                9.994803e-10                       0.0   \n",
       "4                9.994803e-10                       0.0   \n",
       "\n",
       "   predator_life_span_normalized  predator_diet_Carnivore  \\\n",
       "0                       0.009066                      0.0   \n",
       "1                       0.009066                      0.0   \n",
       "2                       0.009066                      0.0   \n",
       "3                       0.009066                      0.0   \n",
       "4                       0.009066                      0.0   \n",
       "\n",
       "   predator_diet_Herbivore  predator_diet_Insectivore  ...  \\\n",
       "0                      0.0                        1.0  ...   \n",
       "1                      0.0                        1.0  ...   \n",
       "2                      0.0                        1.0  ...   \n",
       "3                      0.0                        1.0  ...   \n",
       "4                      0.0                        1.0  ...   \n",
       "\n",
       "   prey_habitat_Meadow  prey_habitat_Gardens  prey_habitat_other  \\\n",
       "0                  1.0                   0.0                 1.0   \n",
       "1                  1.0                   0.0                 1.0   \n",
       "2                  0.0                   1.0                 1.0   \n",
       "3                  0.0                   0.0                 1.0   \n",
       "4                  0.0                   0.0                 0.0   \n",
       "\n",
       "   prey_continent_Europe  prey_continent_Asia  prey_continent_Africa  \\\n",
       "0                    1.0                  1.0                    0.0   \n",
       "1                    1.0                  1.0                    1.0   \n",
       "2                    1.0                  1.0                    1.0   \n",
       "3                    1.0                  0.0                    1.0   \n",
       "4                    1.0                  1.0                    0.0   \n",
       "\n",
       "   prey_continent_North_America  prey_continent_Central_America  \\\n",
       "0                           1.0                             0.0   \n",
       "1                           1.0                             0.0   \n",
       "2                           0.0                             0.0   \n",
       "3                           0.0                             0.0   \n",
       "4                           1.0                             0.0   \n",
       "\n",
       "   prey_continent_South_America  prey_continent_Oceania  \n",
       "0                           0.0                     0.0  \n",
       "1                           1.0                     1.0  \n",
       "2                           0.0                     0.0  \n",
       "3                           0.0                     0.0  \n",
       "4                           1.0                     0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_with_all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}